{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on new images\n",
    "This notebook will walk you step by step through the process of using a pre-trained model to detect traffic signs in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import glob as glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Alive\\\\Downloads\\\\new\\\\traffic-sign-detection-master', 'D:\\\\Anaconda3\\\\python37.zip', 'D:\\\\Anaconda3\\\\DLLs', 'D:\\\\Anaconda3\\\\lib', 'D:\\\\Anaconda3', '', 'D:\\\\Anaconda3\\\\lib\\\\site-packages', 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32', 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\Alive\\\\Traffic-Signs-Detect-German-master\\\\models\\\\research', 'C:\\\\Users\\\\Alive\\\\Traffic-Signs-Detect-German-master\\\\models\\\\research\\\\slim', 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Alive\\\\.ipython', 'C:\\\\Users\\\\Alive\\\\Traffic-Signs-Detect-German-master\\\\models11.13\\\\research\\\\object_detection', 'C:\\\\Users\\\\Alive\\\\Traffic-Signs-Detect-German-master\\\\darkflow\\\\darkflow-master']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "# Append your Tensorflow object detection and darkflow directories to your path\n",
    "sys.path.append('C:\\\\Users\\\\Alive\\\\Traffic-Signs-Detect-German-master\\\\models11.13\\\\research\\\\object_detection') # ~/tensorflow/models/research/object_detection\n",
    "sys.path.append('C:\\\\Users\\\\Alive\\\\Traffic-Signs-Detect-German-master\\\\darkflow\\\\darkflow-master') # ~/darkflow\n",
    "print(sys.path)\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous'\n",
    "MODEL_NAME = 'faster_rcnn_resnet_101'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "# MODEL_NAME = 'faster_rcnn_inception_v2'\n",
    "# MODEL_NAME = 'rfcn_resnet101'\n",
    "# MODEL_NAME = 'ssd_inception_v2'\n",
    "# MODEL_NAME = 'ssd_mobilenet_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Alive/Downloads/new/traffic-sign-detection-master/models/faster_rcnn_resnet_101/inference_graph/frozen_inference_graph.pb\n",
      "C:/Users/Alive/Downloads/new/traffic-sign-detection-master/scripts/gtsdb3_label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the traffic sign detection.\n",
    "# MODEL_PATH = os.path.join('models', MODEL_NAME)\n",
    "PATH_TO_CKPT = \"C:/Users/Alive/Downloads/new/traffic-sign-detection-master/models/faster_rcnn_resnet_101/inference_graph/frozen_inference_graph.pb\"\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = \"C:/Users/Alive/Downloads/new/traffic-sign-detection-master/scripts/gtsdb3_label_map.pbtxt\"\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "print(PATH_TO_CKPT)\n",
    "print(PATH_TO_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `2`, we know that this corresponds to `mandatory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1122 16:14:48.964518 41060 deprecation_wrapper.py:119] From C:\\Users\\Alive\\Traffic-Signs-Detect-German-master\\models11.13\\research\\object_detection\\utils\\label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item {\n",
      "  name: \"prohibitory\"\n",
      "  id: 1\n",
      "}\n",
      "item {\n",
      "  name: \"mandatory\"\n",
      "  id: 2\n",
      "}\n",
      "item {\n",
      "  name: \"danger\"\n",
      "  id: 3\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Alive\\\\Downloads\\\\new\\\\traffic-sign-detection-master\\\\test_images\\\\00702.png', 'C:\\\\Users\\\\Alive\\\\Downloads\\\\new\\\\traffic-sign-detection-master\\\\test_images\\\\00706.png', 'C:\\\\Users\\\\Alive\\\\Downloads\\\\new\\\\traffic-sign-detection-master\\\\test_images\\\\00713.png', 'C:\\\\Users\\\\Alive\\\\Downloads\\\\new\\\\traffic-sign-detection-master\\\\test_images\\\\00716.png']\n"
     ]
    }
   ],
   "source": [
    "# For the sake of simplicity we will use only 2 images:\n",
    "# image1.jpg\n",
    "# image2.jpg\n",
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = 'C:\\\\Users\\\\Alive\\\\Downloads\\\\new\\\\traffic-sign-detection-master\\\\test_images'\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.ppm'))\n",
    "print(TEST_IMAGE_PATHS)\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "          # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "                'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                      tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "          # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im_width, im_height: 1024 768\n",
      "new_xmin,new_xmax,new_ymin,new_ymax: 569 603 372 404\n",
      "im_width, im_height: 1024 768\n",
      "new_xmin,new_xmax,new_ymin,new_ymax: 529 546 506 524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1122 16:16:08.646233 41060 deprecation_wrapper.py:119] From C:\\Users\\Alive\\Traffic-Signs-Detect-German-master\\models11.13\\research\\object_detection\\utils\\visualization_utils.py:77: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alive\\Downloads\\new\\traffic-sign-detection-master\\test_images\\00702.png\n",
      "C:\\Users\\Alive\\Downloads\\new\\traffic-sign-detection-master\\test_images\\00706.png\n",
      "im_width, im_height: 1280 720\n",
      "new_xmin,new_xmax,new_ymin,new_ymax: 844 888 200 242\n",
      "C:\\Users\\Alive\\Downloads\\new\\traffic-sign-detection-master\\test_images\\00713.png\n",
      "im_width, im_height: 1024 768\n",
      "new_xmin,new_xmax,new_ymin,new_ymax: 578 745 62 218\n",
      "C:\\Users\\Alive\\Downloads\\new\\traffic-sign-detection-master\\test_images\\00716.png\n"
     ]
    }
   ],
   "source": [
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    image= Image.open(image_path) #注意这里的image_path是个路径，也就是说是个字符串str，下文会用到\n",
    "  # the array based representation of the image will be used later in order to prepare the\n",
    "  # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "  # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "  # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      image_path, #原有的代码没有这一行，但是我需要传递测试图片image的文件名给visualize_utils文件中，所以加上，对应的visualize_utils中的visualize_boxes_and_labels_on_image_array函数也要加上这个参数\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks'),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=1, #默认的框到粗细是8，但是实在太粗了\n",
    "      )#the width of bounding box,default is 8\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)\n",
    "    #save_dir = TEST_IMAGE_PATHS + '{}.jpg'.format(image_path)\n",
    "    PATH_TO_TEST_IMAGES_1_DIR = r'C:\\\\Users\\\\Alive\\\\Downloads\\\\new\\\\traffic-sign-detection-master\\\\test_images' #这里可能要加上r，不然可能会有编码ucf8错误\n",
    "    save_dir = os.path.join(PATH_TO_TEST_IMAGES_1_DIR, image_path)\n",
    "    print(save_dir)\n",
    "    vis_util.save_image_array_as_png(image_np,save_dir) #我将检测出来的图片保存在testsave_images文件夹下\n",
    "     \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alive\\Downloads\\new\\traffic-sign-detection-master\\test_images\\00702.png\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "visualize_boxes_and_labels_on_image_array() missing 1 required positional argument: 'category_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1d03fe107bc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mcategory_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0muse_normalized_coordinates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 line_thickness=6)\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: visualize_boxes_and_labels_on_image_array() missing 1 required positional argument: 'category_index'"
     ]
    }
   ],
   "source": [
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            print(image_path)\n",
    "            image = Image.open(image_path)\n",
    "            # the array based representation of the image will be used later in order to prepare the\n",
    "            # result image with boxes and labels on it.\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=6)\n",
    "            plt.figure(idx, figsize=IMAGE_SIZE)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image_np)\n",
    "#             print(image_np.shape)\n",
    "#             print(boxes.shape)\n",
    "#             plt.imshow(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darkflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "import cv2\n",
    "\n",
    "MODEL_PATH = os.path.join(\"C:/Users/Alive/Downloads/new/traffic-sign-detection-master/models/\")\n",
    "\n",
    "options = {'model': os.path.join(MODEL_PATH, 'yolo_v2.cfg'),\n",
    "           'labels': os.path.join(MODEL_PATH, 'labels.txt'),\n",
    "           'backup': MODEL_PATH,\n",
    "           'load' : 50500,\n",
    "           'threshold': 0.5,\n",
    "           'gpu' : 1.0}\n",
    "\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rectangle(bbox, ax, class_name, edgecolor, confidence=None):\n",
    "    xmin = bbox[0]\n",
    "    ymin = bbox[1]\n",
    "    xmax = bbox[2]\n",
    "    ymax = bbox[3]\n",
    "    left = xmin\n",
    "    right = xmax\n",
    "    top = ymin\n",
    "    bot = ymax\n",
    "    ax.add_patch(\n",
    "        plt.Rectangle((left, top),\n",
    "                      right-left,\n",
    "                      bot-top, fill=False,\n",
    "                      edgecolor=edgecolor, linewidth=3.5)\n",
    "        )\n",
    "    label = '{:s}'.format(class_name)\n",
    "    label_pos_y = top-10\n",
    "    if confidence:\n",
    "        label += ' {0:.2f}'.format(confidence)\n",
    "        label_pos_y = bot+20\n",
    "    ax.text(left, label_pos_y,label,\n",
    "            bbox=dict(facecolor=edgecolor, alpha=0.5),\n",
    "            fontsize=14, color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_id(label_name):\n",
    "    for category in categories:\n",
    "        if category['name'] == label_name:\n",
    "            return category['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score_thresh = 0.5\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    print(image_path)\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    image = Image.open(image_path)\n",
    "    image_name = os.path.basename(image_path)\n",
    "    width, height = image.size\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    image_np = image_np[:,:,::-1] # rgb -> bgr\n",
    "    pred_results = tfnet.return_predict(image_np)\n",
    "\n",
    "    for idx, det in enumerate(pred_results):\n",
    "        score = det['confidence']\n",
    "        if score > min_score_thresh:\n",
    "            bbox = det['topleft']['x'], det['topleft']['y'], det['bottomright']['x'], det['bottomright']['y']\n",
    "            label = get_label_id(det['label'])\n",
    "            plot_rectangle(bbox,ax,category_index[label]['name'],'red', score)\n",
    "    plt.draw()\n",
    "    fig.tight_layout()\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
